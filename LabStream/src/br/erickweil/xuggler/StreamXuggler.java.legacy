/*
 * To change this license header, choose License Headers in Project Properties.
 * To change this template file, choose Tools | Templates
 * and open the template in the editor.
 */
package br.erickweil.xuggler;

import br.erickweil.webserver.ProtocolFactory;
import br.erickweil.webserver.ServerHttpProxy;
import br.erickweil.webserver.ServerProtocol;
import br.erickweil.webserver.WebClient;
import br.erickweil.webserver.WebServer;
import com.xuggle.mediatool.IMediaReader;
import com.xuggle.mediatool.IMediaViewer;
import com.xuggle.mediatool.IMediaWriter;
import com.xuggle.mediatool.ToolFactory;
import com.xuggle.xuggler.Global;
import com.xuggle.xuggler.ICodec;
import com.xuggle.xuggler.IContainer;
import com.xuggle.xuggler.IContainerFormat;
import com.xuggle.xuggler.IPacket;
import com.xuggle.xuggler.IPixelFormat;
import com.xuggle.xuggler.IRational;
import com.xuggle.xuggler.IStream;
import com.xuggle.xuggler.IStreamCoder;
import com.xuggle.xuggler.IVideoPicture;
import com.xuggle.xuggler.IVideoResampler;
import com.xuggle.xuggler.Utils;
import com.xuggle.xuggler.demos.VideoImage;
import com.xuggle.xuggler.io.XugglerIO;
import com.xuggle.xuggler.video.ConverterFactory;
import com.xuggle.xuggler.video.IConverter;
import java.awt.Rectangle;
import java.awt.Robot;
import java.awt.Toolkit;
import java.awt.image.BufferedImage;
import java.io.BufferedOutputStream;
import java.io.DataInput;
import java.io.DataOutput;
import java.io.FileOutputStream;
import java.io.IOException;
import java.io.InputStream;
import java.io.OutputStream;
import java.util.concurrent.TimeUnit;

/**
 *
 * @author Usuario
 */
public class StreamXuggler {
  private static IRational FRAME_RATE=IRational.make(10,2);
  private static int millis_to_wait = (int)(1000.0/FRAME_RATE.getDouble());
  private static final int SECONDS_TO_RUN_FOR = 10;

  public static ServerProtocol getClientProtocol() {
        return new ServerProtocol() {
            @Override
            public void processRequest() throws IOException {
                try {
                    //System.out.println("started client.");
                    //IMediaReader mediaReader = ToolFactory.makeReader(XugglerIO.map((DataInput)input));
                    //System.out.println("created reader.");
                    //IMediaViewer mediaViewer = ToolFactory.makeViewer(IMediaViewer.Mode.VIDEO_ONLY,true);
                    //System.out.println("created viewer.");
                    //mediaReader.addListener(mediaViewer);
                    //System.out.println("added listener.");
                    //while (mediaReader.readPacket() == null)
                    //{
                    //    System.out.println("readed packet;");
                    //}
                    VideoImage mScreen = null;

    // Let's make sure that we can actually convert video pixel formats.
    if (!IVideoResampler.isSupported(
        IVideoResampler.Feature.FEATURE_COLORSPACECONVERSION))
      throw new RuntimeException("you must install the GPL version" +
      		" of Xuggler (with IVideoResampler support) for " +
      		"this demo to work");

    // Create a Xuggler container object
    IContainerFormat containerFormat = IContainerFormat.make();
                    containerFormat.setInputFormat("flv");
    IContainer container = IContainer.make(containerFormat);
    System.out.println("Montou Container.");
    // Open up the container
    if (container.open(input, containerFormat) < 0)
      throw new IllegalArgumentException("could not open stream");
    System.out.println("Abriu Container.");
    // query how many streams the call to open found
    int numStreams = container.getNumStreams();

    // and iterate through the streams to find the first video stream
    int videoStreamId = -1;
    IStreamCoder videoCoder = null;
    for(int i = 0; i < numStreams; i++)
    {
      // Find the stream object
      IStream stream = container.getStream(i);
      // Get the pre-configured decoder that can decode this stream;
      IStreamCoder coder = stream.getStreamCoder();

      if (coder.getCodecType() == ICodec.Type.CODEC_TYPE_VIDEO)
      {
        videoStreamId = i;
        videoCoder = coder;
        break;
      }
    }
    if (videoStreamId == -1)
      throw new RuntimeException("could not find video stream in container: ");

    /*
     * Now we have found the video stream in this file.  Let's open up our decoder so it can
     * do work.
     */
    if (videoCoder.open() < 0)
      throw new RuntimeException("could not open video decoder for container: ");
    System.out.println("Abriu Video Coder.");
    IVideoResampler resampler = null;
    if (videoCoder.getPixelType() != IPixelFormat.Type.BGR24)
    {
      // if this stream is not in BGR24, we're going to need to
      // convert it.  The VideoResampler does that for us.
      resampler = IVideoResampler.make(videoCoder.getWidth(), 
          videoCoder.getHeight(), IPixelFormat.Type.BGR24,
          videoCoder.getWidth(), videoCoder.getHeight(), videoCoder.getPixelType());
      if (resampler == null)
        throw new RuntimeException("could not create color space " +
        		"resampler for: ");
    }
    /*
     * And once we have that, we draw a window on screen
     */
    mScreen = new VideoImage();

    /*
     * Now, we start walking through the container looking at each packet.
     */
    IPacket packet = IPacket.make();
    System.out.println("Criou Packet.");
    long firstTimestampInStream = Global.NO_PTS;
    long systemClockStartTime = 0;
    System.out.println("Se preparando.");
    while(container.readNextPacket(packet) >= 0)
    {
        System.out.println("Chegou.");
      /*
       * Now we have a packet, let's see if it belongs to our video stream
       */
      if (packet.getStreamIndex() == videoStreamId)
      {
        /*
         * We allocate a new picture to get the data out of Xuggler
         */
        IVideoPicture picture = IVideoPicture.make(videoCoder.getPixelType(),
            videoCoder.getWidth(), videoCoder.getHeight());

        int offset = 0;
        while(offset < packet.getSize())
        {
            System.out.println("decoding.");
          /*
           * Now, we decode the video, checking for any errors.
           * 
           */
          int bytesDecoded = videoCoder.decodeVideo(picture, packet, offset);
          if (bytesDecoded < 0)
            throw new RuntimeException("got error decoding video in: ");
          offset += bytesDecoded;

          /*
           * Some decoders will consume data in a packet, but will not be able to construct
           * a full video picture yet.  Therefore you should always check if you
           * got a complete picture from the decoder
           */
          if (picture.isComplete())
          {
              System.out.println("pic complete.");
            IVideoPicture newPic = picture;
            /*
             * If the resampler is not null, that means we didn't get the
             * video in BGR24 format and
             * need to convert it into BGR24 format.
             */
            if (resampler != null)
            {
              // we must resample
              newPic = IVideoPicture.make(resampler.getOutputPixelFormat(),
                  picture.getWidth(), picture.getHeight());
              if (resampler.resample(newPic, picture) < 0)
                throw new RuntimeException("could not resample video from: ");
            }
            if (newPic.getPixelType() != IPixelFormat.Type.BGR24)
              throw new RuntimeException("could not decode video" +
              		" as BGR 24 bit data in: ");

            /**
             * We could just display the images as quickly as we decode them,
             * but it turns out we can decode a lot faster than you think.
             * 
             * So instead, the following code does a poor-man's version of
             * trying to match up the frame-rate requested for each
             * IVideoPicture with the system clock time on your computer.
             * 
             * Remember that all Xuggler IAudioSamples and IVideoPicture objects
             * always give timestamps in Microseconds, relative to the first
             * decoded item. If instead you used the packet timestamps, they can
             * be in different units depending on your IContainer, and IStream
             * and things can get hairy quickly.
             */
            if (firstTimestampInStream == Global.NO_PTS)
            {
              // This is our first time through
              firstTimestampInStream = picture.getTimeStamp();
              // get the starting clock time so we can hold up frames
              // until the right time.
              systemClockStartTime = System.currentTimeMillis();
            } else {
              long systemClockCurrentTime = System.currentTimeMillis();
              long millisecondsClockTimeSinceStartofVideo =
                systemClockCurrentTime - systemClockStartTime;
              // compute how long for this frame since the first frame in the
              // stream.
              // remember that IVideoPicture and IAudioSamples timestamps are
              // always in MICROSECONDS,
              // so we divide by 1000 to get milliseconds.
              long millisecondsStreamTimeSinceStartOfVideo =
                (picture.getTimeStamp() - firstTimestampInStream)/1000;
              final long millisecondsTolerance = 50; // and we give ourselfs 50 ms of tolerance
              final long millisecondsToSleep = 
                (millisecondsStreamTimeSinceStartOfVideo -
                  (millisecondsClockTimeSinceStartofVideo +
                      millisecondsTolerance));
              if (millisecondsToSleep > 0)
              {
                try
                {
                  Thread.sleep(millisecondsToSleep);
                }
                catch (InterruptedException e)
                {
                  // we might get this when the user closes the dialog box, so
                  // just return from the method.
                  return;
                }
              }
            }

            // And finally, convert the BGR24 to an Java buffered image
            BufferedImage javaImage = Utils.videoPictureToImage(newPic);

            // and display it on the Java Swing window
            mScreen.setImage(javaImage);
          }
        }
      }
      else
      {
        /*
         * This packet isn't part of our video stream, so we just
         * silently drop it.
         */
        //do {} while(false);
          System.out.println("Chegou Errado.");
      }

    }
    /*
     * Technically since we're exiting anyway, these will be cleaned up by 
     * the garbage collector... but because we're nice people and want
     * to be invited places for Christmas, we're going to show how to clean up.
     */
    if (videoCoder != null)
    {
      videoCoder.close();
      videoCoder = null;
    }
    if (container !=null)
    {
      container.close();
      container = null;
    }
    mScreen.dispose();
                }
                catch(Exception e)
                {
                    e.printStackTrace();
                }
                finally
                {
                    System.out.println("ended client.");    
                }
                
            }
        };
   }
  
    public static ServerProtocol getServerProtocol() {
        return new ServerProtocol() {
            @Override
            public void processRequest() throws IOException {
                try {
                    // This is the robot for taking a snapshot of the
                    // screen.  It's part of Java AWT
                    final Robot robot = new Robot();
                    //HWND desktopWindow = User32.INSTANCE.GetDesktopWindow();
                    final Toolkit toolkit = Toolkit.getDefaultToolkit();
                    final Rectangle screenBounds = new Rectangle(toolkit.getScreenSize());
                    //BufferedImage bufferImg = JNAScreenShotter.createImg(screenBounds);

                    /*
                    // First, let's make a IMediaWriter to write the file.
                    final IContainer container = IContainer.make();
                    if (container.open(outFile, IContainer.Type.WRITE, null) <0) 
                    throw new RuntimeException("failed to open");  
                     */
                    //final IMediaWriter writer = ToolFactory.makeWriter(outFile);
                    //BufferedOutputStream bout = new BufferedOutputStream(new FileOutputStream(outFile));
                    //DataOutputStream stream = new DataOutputStream(bout);
                    IContainerFormat containerFormat = IContainerFormat.make();
                    containerFormat.setOutputFormat("flv", null, "video/x-flv");
                    //containerFormat.setOutputFormat("mp4", null, "video/mp4");

                    //  IContainer container = IContainer.make(containerFormat);
                    IContainer container = IContainer.make(containerFormat);
                    container.open(XugglerIO.map((DataOutput)output), IContainer.Type.WRITE, containerFormat);

                    //		create the video stream and get its coder
		ICodec videoCodec = ICodec.findEncodingCodec(ICodec.ID.CODEC_ID_H264);
		IStream videoStream = container.addNewStream(videoCodec);
		IStreamCoder videoStreamCoder = videoStream.getStreamCoder();
                    
                videoStreamCoder.setWidth(screenBounds.width);
		videoStreamCoder.setHeight(screenBounds.height);
		videoStreamCoder.setFrameRate(FRAME_RATE);
		videoStreamCoder.setTimeBase(IRational.make(FRAME_RATE.getDenominator(),
				FRAME_RATE.getNumerator()));
		videoStreamCoder.setBitRate(350000);
		videoStreamCoder.setNumPicturesInGroupOfPictures(5);
		videoStreamCoder.setPixelType(IPixelFormat.Type.YUV420P);
                //videoStreamCoder.setPixelType(IPixelFormat.Type.BGR24);
		videoStreamCoder.setFlag(IStreamCoder.Flags.FLAG_QSCALE, true);
                
		videoStreamCoder.setGlobalQuality(0);
                
                //		open the coder first
		videoStreamCoder.open(null, null);
		
//		write the header
		container.writeHeader();
                
                  
                    // Now, we're going to loop
                    long startTime = System.nanoTime();
                    System.out.println(FRAME_RATE.getDouble());
                    for (int index = 0; index < SECONDS_TO_RUN_FOR * FRAME_RATE.getDouble(); index++) {
                        // take the screen shot
                        long measure = System.nanoTime();
                        BufferedImage screen = robot.createScreenCapture(screenBounds);

                        //assertNotNull("Failed to obtain desktop window handle", desktopWindow);
                        //BufferedImage screen = GDI32Util.getScreenshot(desktopWindow);
                        //BufferedImage screen = JNAScreenShotter.getScreenshot(desktopWindow,screenBounds,bufferImg);
                        double diff1 = (double) (System.nanoTime() - measure) / 1_000_000.0;
                        // convert to the right image type
                        BufferedImage bgrScreen = convertToType(screen,
                                BufferedImage.TYPE_3BYTE_BGR);

                        measure = System.nanoTime();
                        // encode the image
                        
                        //			now, create a packet
			IPacket packet = IPacket.make();
			
			IConverter converter = ConverterFactory.createConverter(bgrScreen, 
					videoStreamCoder.getPixelType());
			
			IVideoPicture frame = converter.toPicture(bgrScreen, (System.nanoTime() - startTime) / 1000);
			frame.setQuality(0);
			
			if (videoStreamCoder.encodeVideo(packet, frame, 0) < 0) {
				throw new RuntimeException("Unable to encode video.");
			}
			
			if (packet.isComplete()) {
                            System.out.println("Writed packet");
				if (container.writePacket(packet) < 0) {
					throw new RuntimeException("Could not write packet to container.");
				}
			}

                        
                        double diff2 = (double) (System.nanoTime() - measure) / 1_000_000.0;

                        System.out.println("encoded image: " + index + "\t" + diff1 + "\t" + diff2);
                        
                        // sleep for framerate milliseconds
                        //output.flush();
                        Thread.sleep(Math.max(0, millis_to_wait - (int) (diff1 + diff2)));
                        
                    }
                    // Finally we tell the writer to close and write the trailer if
                    // needed
//		done, so now let's wrap this up.		
		container.writeTrailer();
		
		videoStreamCoder.close();
//		container.flushPackets();
		container.close();
                } catch (Throwable e) {
                    e.printStackTrace();
                    System.err.println("an error occurred: " + e.getMessage());
                }
            }
        };
    }
  
  /**
   * Takes a screen shot of your entire screen and writes it to
   * output.flv
   * 
   * @param args
   */
    public static void main(String[] args) {

        new Thread(new Runnable() {
            @Override
            public void run() {
                WebServer server = new WebServer(8080, new ProtocolFactory() {
                    @Override
                    public ServerProtocol get() {
                        return getServerProtocol();
                    }
                });
                try {
                    server.run();
                } catch (Throwable e) {
                    // TODO Auto-generated catch block
                    e.printStackTrace();
                }
            }
        }).start();
        
        new Thread(new Runnable() {
            @Override
            public void run() {
                WebClient client = new WebClient("localhost",8080, new ProtocolFactory() {
                    @Override
                    public ServerProtocol get() {
                        return getClientProtocol();
                    }
                });
                try {
                    client.run();
                } catch (Throwable e) {
                    // TODO Auto-generated catch block
                    e.printStackTrace();
                }
            }
        }).start();

    }

    /**
   * Convert a {@link BufferedImage} of any type, to {@link BufferedImage} of a
   * specified type. If the source image is the same type as the target type,
   * then original image is returned, otherwise new image of the correct type is
   * created and the content of the source image is copied into the new image.
   * 
   * @param sourceImage
   *          the image to be converted
   * @param targetType
   *          the desired BufferedImage type
   * 
   * @return a BufferedImage of the specifed target type.
   * 
   * @see BufferedImage
   */

  public static BufferedImage convertToType(BufferedImage sourceImage,
      int targetType)
  {
    BufferedImage image;

    // if the source image is already the target type, return the source image

    if (sourceImage.getType() == targetType)
      image = sourceImage;

    // otherwise create a new image of the target type and draw the new
    // image

    else
    {
      image = new BufferedImage(sourceImage.getWidth(),
          sourceImage.getHeight(), targetType);
      image.getGraphics().drawImage(sourceImage, 0, 0, null);
    }

    return image;
  }

}
